{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "6EIN2z01r_0a",
        "outputId": "fbad0cd7-5cea-414a-858d-fd02be282373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face-Mask-Detection-'...\n",
            "remote: Enumerating objects: 4547, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 4547 (delta 11), reused 0 (delta 0), pack-reused 4523 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4547/4547), 176.67 MiB | 24.90 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "Updating files: 100% (4678/4678), done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Dataset directory not found in known paths. Check the repository structure.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f0c1f52e6420>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset directory not found in known paths. Check the repository structure.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Dataset directory not found in known paths. Check the repository structure."
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Step 1: Business Understanding (CRISP-DM Step 1)\n",
        "# Goal: Classify images as 'with_mask' or 'without_mask' using transfer learning with a pretrained VGG16 model.\n",
        "\n",
        "# Step 2: Data Understanding (CRISP-DM Step 2)\n",
        "# Clone the dataset repository from GitHub\n",
        "repo_dir = \"Face-Mask-Detection-\"\n",
        "if os.path.exists(repo_dir):\n",
        "    shutil.rmtree(repo_dir)  # Remove existing directory to avoid conflicts\n",
        "!git clone https://github.com/chauhanarpit09/Face-Mask-Detection-.git\n",
        "\n",
        "# Verify dataset paths\n",
        "possible_dirs = [\"Face-Mask-Detection-/Dataset\", \"Face-Mask-Detection-/data\", \"Face-Mask-Detection-/Face Mask Dataset\"]\n",
        "base_dir = None\n",
        "for dir_option in possible_dirs:\n",
        "    if os.path.exists(dir_option):\n",
        "        base_dir = dir_option\n",
        "        break\n",
        "if base_dir is None:\n",
        "    raise FileNotFoundError(\"Dataset directory not found in known paths. Check the repository structure.\")\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "val_dir = os.path.join(base_dir, 'Validation')\n",
        "test_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    train_dir = os.path.join(base_dir, 'train')\n",
        "if not os.path.exists(val_dir):\n",
        "    val_dir = os.path.join(base_dir, 'validation')\n",
        "if not os.path.exists(test_dir):\n",
        "    test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir) or not os.path.exists(val_dir) or not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"One or more dataset directories (Train, Validation, Test) are missing.\")\n",
        "\n",
        "# Step 3: Data Preparation (CRISP-DM Step 3)\n",
        "# Prepare ImageDataGenerators\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Step 4: Modeling (CRISP-DM Step 4)\n",
        "# Load pretrained VGG16 model without the top layer\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "vgg16_base.trainable = False\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    vgg16_base,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Evaluation (CRISP-DM Step 5)\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Step 6: Deployment (CRISP-DM Step 6)\n",
        "def test_image(image_url, model, class_names):\n",
        "    import requests\n",
        "    from PIL import Image\n",
        "    from io import BytesIO\n",
        "\n",
        "    response = requests.get(image_url)\n",
        "    img = Image.open(BytesIO(response.content)).resize((224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = class_names[int(predictions[0] > 0.5)]\n",
        "    print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "# Example Usage\n",
        "image_url = input(\"Enter image URL: \")\n",
        "test_image(image_url, model, ['without_mask', 'with_mask'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Find dataset directory\n",
        "def find_dataset_dir(base_path):\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        if 'train' in dirs and 'test' in dirs:\n",
        "            return root\n",
        "    return None\n",
        "\n",
        "# Clone repository if not exists\n",
        "if not os.path.exists('/content/Face-Mask-Detection-'):\n",
        "    !git clone https://github.com/chauhanarpit09/Face-Mask-Detection-.git\n",
        "\n",
        "# Find dataset directory\n",
        "dataset_base_path = find_dataset_dir('/content/Face-Mask-Detection-')\n",
        "\n",
        "if dataset_base_path:\n",
        "    train_dir = os.path.join(dataset_base_path, 'train')\n",
        "    validation_dir = os.path.join(dataset_base_path, 'test')\n",
        "else:\n",
        "    # Fallback to manual path specification\n",
        "    train_dir = '/content/Face-Mask-Detection-/train'\n",
        "    validation_dir = '/content/Face-Mask-Detection-/test'\n",
        "\n",
        "print(f\"Train Directory: {train_dir}\")\n",
        "print(f\"Validation Directory: {validation_dir}\")\n",
        "\n",
        "# Verify directories exist\n",
        "print(\"Train Directory Contents:\")\n",
        "print(os.listdir(train_dir))\n",
        "print(\"\\nValidation Directory Contents:\")\n",
        "print(os.listdir(validation_dir))\n",
        "\n",
        "# Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkxlsiXBudTT",
        "outputId": "07602245-ba3c-47be-8db4-f59591dab043"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Directory: /content/Face-Mask-Detection-/facemask/train\n",
            "Validation Directory: /content/Face-Mask-Detection-/facemask/test\n",
            "Train Directory Contents:\n",
            "['without_mask', 'with_mask']\n",
            "\n",
            "Validation Directory Contents:\n",
            "['without_mask', 'with_mask']\n",
            "Found 3437 images belonging to 2 classes.\n",
            "Found 14 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Face Mask Detection Project Setup and Diagnostics\n",
        "\n",
        "# 1. Install necessary libraries\n",
        "!pip install tensorflow keras numpy matplotlib\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 2. Clone the repository\n",
        "!git clone https://github.com/chauhanarpit09/Face-Mask-Detection-.git\n",
        "\n",
        "# 3. Diagnostic Function to Explore Repository\n",
        "def explore_repository(base_path):\n",
        "    print(\"🔍 Repository Structure Exploration:\")\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        level = root.replace(base_path, '').count(os.sep)\n",
        "        indent = ' ' * 4 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 4 * (level + 1)\n",
        "        for dir in dirs:\n",
        "            print(f\"{subindent}{dir}/\")\n",
        "        for file in files[:5]:  # Limit to first 5 files\n",
        "            print(f\"{subindent}{file}\")\n",
        "\n",
        "# 4. Find Dataset Directory\n",
        "def find_dataset_directories(base_path):\n",
        "    dataset_dirs = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        if 'train' in dirs or 'test' in dirs:\n",
        "            dataset_dirs.append(root)\n",
        "    return dataset_dirs\n",
        "\n",
        "# 5. Repository Exploration\n",
        "print(\"📂 Exploring Repository Directories:\")\n",
        "explore_repository('/content/Face-Mask-Detection-')\n",
        "\n",
        "# 6. Find Potential Dataset Directories\n",
        "potential_dataset_paths = find_dataset_directories('/content/Face-Mask-Detection-')\n",
        "print(\"\\n📊 Potential Dataset Paths:\")\n",
        "for path in potential_dataset_paths:\n",
        "    print(path)\n",
        "\n",
        "# 7. Attempt to Locate Train and Test Directories\n",
        "def locate_train_test_dirs(base_path):\n",
        "    train_dirs = []\n",
        "    test_dirs = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        if 'train' in dirs:\n",
        "            train_dirs.append(os.path.join(root, 'train'))\n",
        "        if 'test' in dirs:\n",
        "            test_dirs.append(os.path.join(root, 'test'))\n",
        "    return train_dirs, test_dirs\n",
        "\n",
        "train_directories, test_directories = locate_train_test_dirs('/content/Face-Mask-Detection-')\n",
        "\n",
        "print(\"\\n🔬 Detected Train Directories:\")\n",
        "for dir in train_directories:\n",
        "    print(dir)\n",
        "    print(\"  Contents:\", os.listdir(dir)[:5])\n",
        "\n",
        "print(\"\\n🔬 Detected Test Directories:\")\n",
        "for dir in test_directories:\n",
        "    print(dir)\n",
        "    print(\"  Contents:\", os.listdir(dir)[:5])\n",
        "\n",
        "# If multiple paths found, we'll use the first valid path\n",
        "train_dir = train_directories[0] if train_directories else None\n",
        "test_dir = test_directories[0] if test_directories else None\n",
        "\n",
        "# 8. Data Generator Setup (Flexible)\n",
        "if train_dir and test_dir:\n",
        "    print(\"\\n🚀 Setting Up Data Generators...\")\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "    # 9. Model Building\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # 10. Model Compilation\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # 11. Model Training\n",
        "    print(\"\\n🏋️ Training Model...\")\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "        epochs=5\n",
        "    )\n",
        "\n",
        "    # 12. Model Evaluation\n",
        "    print(\"\\n📊 Model Evaluation:\")\n",
        "    evaluation = model.evaluate(validation_generator)\n",
        "    print(f\"Test Loss: {evaluation[0]}\")\n",
        "    print(f\"Test Accuracy: {evaluation[1]}\")\n",
        "else:\n",
        "    print(\"❌ Could not locate train and test directories!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FExgmWEvoi_",
        "outputId": "5cde011c-3635-4957-dd5d-affe7f9acc7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Cloning into 'Face-Mask-Detection-'...\n",
            "remote: Enumerating objects: 4547, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 4547 (delta 11), reused 0 (delta 0), pack-reused 4523 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4547/4547), 176.67 MiB | 23.03 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "Updating files: 100% (4678/4678), done.\n",
            "📂 Exploring Repository Directories:\n",
            "🔍 Repository Structure Exploration:\n",
            "Face-Mask-Detection-/\n",
            "    face_detector/\n",
            "    facemask/\n",
            "    .git/\n",
            "    README.md\n",
            "    facemaskdetector.py\n",
            "    acc or loss plot.png\n",
            "    facemask.ipynb\n",
            "    Confusion matrix.png\n",
            "    face_detector/\n",
            "        deploy.prototxt\n",
            "        res10_300x300_ssd_iter_140000.caffemodel\n",
            "    facemask/\n",
            "        train/\n",
            "        valid/\n",
            "        test/\n",
            "        train/\n",
            "            without_mask/\n",
            "            with_mask/\n",
            "            without_mask/\n",
            "                augmented_image_251.jpg\n",
            "                1_0_aidai_0058.jpg\n",
            "                1_0_luojin_0044.jpg\n",
            "                augmented_image_94.jpg\n",
            "                434.jpg\n",
            "            with_mask/\n",
            "                with_mask530.jpg\n",
            "                augmented_image_146.jpg\n",
            "                245-with-mask.jpg\n",
            "                with_mask083.jpg\n",
            "                with_mask274.jpg\n",
            "        valid/\n",
            "            without_mask/\n",
            "            with_mask/\n",
            "            without_mask/\n",
            "                0_0_cengyongti_0091.jpg\n",
            "                0_0_aidai_0084.jpg\n",
            "                0_0_caiguoqing_0007.jpg\n",
            "                0_0_chenxuedong_0050.jpg\n",
            "                0_0_anhu_0155.jpg\n",
            "            with_mask/\n",
            "                augmented_image_251.jpg\n",
            "                0_0_0 copy 86.jpg\n",
            "                0_0_0 copy 36.jpg\n",
            "                252-with-mask.jpg\n",
            "                0_0_0 copy 60.jpg\n",
            "        test/\n",
            "            without_mask/\n",
            "            with_mask/\n",
            "            without_mask/\n",
            "                asasa.jpg\n",
            "                asa.jpg\n",
            "                t.jpg\n",
            "                fdfd.jpg\n",
            "                rere.jpg\n",
            "            with_mask/\n",
            "                u.jpg\n",
            "                343-with-mask.jpg\n",
            "                t.jpg\n",
            "                download (1).jpg\n",
            "                nk.jpg\n",
            "    .git/\n",
            "        logs/\n",
            "        info/\n",
            "        branches/\n",
            "        hooks/\n",
            "        refs/\n",
            "        objects/\n",
            "        description\n",
            "        HEAD\n",
            "        index\n",
            "        config\n",
            "        packed-refs\n",
            "        logs/\n",
            "            refs/\n",
            "            HEAD\n",
            "            refs/\n",
            "                remotes/\n",
            "                heads/\n",
            "                remotes/\n",
            "                    origin/\n",
            "                    origin/\n",
            "                        HEAD\n",
            "                heads/\n",
            "                    main\n",
            "        info/\n",
            "            exclude\n",
            "        branches/\n",
            "        hooks/\n",
            "            push-to-checkout.sample\n",
            "            commit-msg.sample\n",
            "            update.sample\n",
            "            pre-commit.sample\n",
            "            pre-rebase.sample\n",
            "        refs/\n",
            "            remotes/\n",
            "            heads/\n",
            "            tags/\n",
            "            remotes/\n",
            "                origin/\n",
            "                origin/\n",
            "                    HEAD\n",
            "            heads/\n",
            "                main\n",
            "            tags/\n",
            "        objects/\n",
            "            info/\n",
            "            pack/\n",
            "            info/\n",
            "            pack/\n",
            "                pack-e2a22aaa9eb44efb613ba75d13cc9a467b448f48.pack\n",
            "                pack-e2a22aaa9eb44efb613ba75d13cc9a467b448f48.idx\n",
            "\n",
            "📊 Potential Dataset Paths:\n",
            "/content/Face-Mask-Detection-/facemask\n",
            "\n",
            "🔬 Detected Train Directories:\n",
            "/content/Face-Mask-Detection-/facemask/train\n",
            "  Contents: ['without_mask', 'with_mask']\n",
            "\n",
            "🔬 Detected Test Directories:\n",
            "/content/Face-Mask-Detection-/facemask/test\n",
            "  Contents: ['without_mask', 'with_mask']\n",
            "\n",
            "🚀 Setting Up Data Generators...\n",
            "Found 3437 images belonging to 2 classes.\n",
            "Found 14 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "🏋️ Training Model...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 19/107\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 369ms/step - accuracy: 0.8065 - loss: 0.3649"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 485ms/step - accuracy: 0.9291 - loss: 0.1545 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
            "Epoch 2/5\n",
            "\u001b[1m  1/107\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9688 - loss: 0.0467"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0467 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 3/5\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 395ms/step - accuracy: 0.9816 - loss: 0.0437 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
            "Epoch 4/5\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9286 - val_loss: 0.1819\n",
            "Epoch 5/5\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 405ms/step - accuracy: 0.9869 - loss: 0.0351 - val_accuracy: 0.9286 - val_loss: 0.4690\n",
            "\n",
            "📊 Model Evaluation:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.0193\n",
            "Test Loss: 0.019338520243763924\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}